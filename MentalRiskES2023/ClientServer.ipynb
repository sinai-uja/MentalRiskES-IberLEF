{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Access the MentalRiskEs data and interact with the server\n","\n","This notebook has been developed by the [SINAI](https://sinai.ujaen.es/) research group for its usage in the [MentalRiskES](https://sites.google.com/view/mentalriskes/) evaluation campaign at IberLEF 2023.\n","\n","**NOTE 1**: Please visit the [MentalRiskES competition website](https://sites.google.com/view/mentalriskes/evaluation) to read the instructions about how to download the data and interact with the server to send the predictions of your system.\n","\n","**NOTE 2**: Along the code, please replace \"URL\" by the URL server and \"TOKEN\" by your personal token.\n","\n","Remember this is a support to help you to develop your own system of communication with our server. We recommend you to download it as a Python script instead of working directly on colab and adapt the code to your needs. "],"metadata":{"id":"ttODwCFd8K0Q"}},{"cell_type":"markdown","source":["# Install CodeCarbon package"],"metadata":{"id":"2DJN0pXx8W3-"}},{"cell_type":"code","source":["!pip install codecarbon"],"metadata":{"id":"wdvPWyc6x9cV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import libraries"],"metadata":{"id":"dqyN-7TcXbL8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sqih7m6tN4MT"},"outputs":[],"source":["import requests, zipfile, io\n","from typing import List, Dict\n","from requests.adapters import HTTPAdapter, Retry\n","import random\n","import json\n","import os\n","import pandas as pd\n","from codecarbon import EmissionsTracker"]},{"cell_type":"markdown","source":["# Endpoints\n","These URL addresses are necessary for the connection to the server. \n","\n","**IMPORTANT:** Replace \"URL\" by the URL server and \"TOKEN\" by your user token."],"metadata":{"id":"CHGGrr3GXdIb"}},{"cell_type":"code","source":["URL = \"\" \n","TOKEN = \"your-token\" \n","\n","# Download endpoints\n","ENDPOINT_DOWNLOAD_MESSAGES_TRIAL = URL+\"{TASK}/download_trial/{TOKEN}\"\n","ENDPOINT_DOWNLOAD_GOLD_TRIAL = URL+\"{SUBTASK}/download_trial/{TOKEN}\"\n","ENDPOINT_DOWNLOAD_MESSAGES_TRAIN = URL+\"{TASK}/download_train/{TOKEN}\"\n","ENDPOINT_DOWNLOAD_GOLD_TRAIN = URL+\"{SUBTASK}/download_train/{TOKEN}\"\n","\n","# Trial endpoints\n","ENDPOINT_GET_MESSAGES_TRIAL = URL+\"{TASK}/getmessages_trial/{TOKEN}\"\n","ENDPOINT_SUBMIT_DECISIONS_TRIAL = URL+\"{SUBTASK}/submit_trial/{TOKEN}/{RUN}\"\n","\n","# Test endpoints\n","ENDPOINT_GET_MESSAGES = URL+\"{TASK}/getmessages/{TOKEN}\"\n","ENDPOINT_SUBMIT_DECISIONS = URL+\"{SUBTASK}/submit/{TOKEN}/{RUN}\""],"metadata":{"id":"AdQPl8lbOKsg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Download Data\n","To download the data, you can make use of the **functions defined in the following**.\n","\n","The following function download the trial data. To adapt it to download the train and test data, follow the instructions given in the [website of the competition](https://sites.google.com/view/mentalriskes/evaluation)."],"metadata":{"id":"WgHNiyxHR5AJ"}},{"cell_type":"code","source":["def download_messages_trial(task: str,subtasks:List[str], token: str) -> List[Dict]:\n","    response = requests.get(ENDPOINT_DOWNLOAD_MESSAGES_TRIAL.format(TASK=task, TOKEN=token))\n","\n","    if response.status_code != 200:\n","        print(\"Trial - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n","    else:\n","      z = zipfile.ZipFile(io.BytesIO(response.content))\n","      os.makedirs(\"./data/{task}/trial/subjects_trial/\".format(task=task))\n","      z.extractall(\"./data/{task}/trial/subjects_trial/\".format(task=task))\n","\n","    for subtask in subtasks:\n","        response = requests.get(ENDPOINT_DOWNLOAD_GOLD_TRIAL.format(SUBTASK=subtask, TOKEN=token))\n","        \n","        if response.status_code != 200:\n","            print(\"Trial - Status Code \" + subtask + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n","        else:\n","          file_object = open(\"./data/{task}/trial/gold_trial_{subtask}.txt\".format(task=task, subtask=subtask), \"w\")\n","          file_object.write(response.text)"],"metadata":{"id":"Uaeh23C5R1lG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Client Server\n","This class simulates communication with our server. The following code established the conection with the server client and simulate the GET and POST requests. \n","\n","**IMPORTANT NOTE:** Please pay attention to the basic functions and remember that it is only a base for your system. "],"metadata":{"id":"VIqRCv3OS3Bn"}},{"cell_type":"code","source":["class Client_taskX:\n","    def __init__(self, task: str, subtasks: List[str], token: str, number_of_runs: int, tracker: EmissionsTracker):\n","        # Task in which you participate\n","        self.task = task\n","        # Subtasks in which you participate\n","        self.subtasks = subtasks\n","        # Token identifier\n","        self.token = token\n","        # Number of runs (Max: 3)\n","        self.number_of_runs = number_of_runs\n","        # Object to calculate CO2 emissions\n","        self.tracker = tracker\n","        self.relevant_cols = ['duration', 'emissions', 'cpu_energy', 'gpu_energy', 'ram_energy', \n","            'energy_consumed', 'cpu_count', 'gpu_count', 'cpu_model', 'gpu_model', 'ram_total_size']\n","\n","    # Here a GET request is sent to the server to extract the data.\n","    def get_messages(self, retries: int, backoff: float) -> Dict:\n","        session = requests.Session()\n","        retries = Retry( \n","                        total = retries,\n","                        backoff_factor = backoff,\n","                        status_forcelist = [500, 502, 503, 504]\n","                        )\n","        session.mount('https://', HTTPAdapter(max_retries=retries))\n","        response = session.get(ENDPOINT_GET_MESSAGES_TRIAL.format(TASK=self.task, TOKEN=self.token))\n","        if response.status_code != 200:\n","          print(\"GET - Status Code \" + self.task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n","          return []\n","        else:\n","          return json.loads(response.content)\n","\n","    # The POST requests are sent to the server to send predictions and carbon emission data\n","    def submit_decission(self, subtask: int, messages: List[Dict], emissions:Dict, retries, backoff):\n","        decisions = {}\n","\n","        # You must create the appropriate structure to send the predictions according to each subtask\n","        for message in messages:\n","            decisions[message[\"nick\"]] = random.randint(0, 1) # the decision of your system according to subtask\n","\n","        data = {\n","            \"predictions\": decisions,\n","            \"emissions\": emissions\n","        }\n","\n","        data = json.dumps(data)\n","        # Session to POST request\n","        session = requests.Session()\n","        retries = Retry(\n","                        total = retries,\n","                        backoff_factor = backoff,\n","                        status_forcelist = [500, 502, 503, 504]\n","                        )\n","        session.mount('https://', HTTPAdapter(max_retries=retries))\n","\n","        for run in range(0,self.number_of_runs):\n","            # For each run, new decisions\n","            response = session.post(ENDPOINT_SUBMIT_DECISIONS_TRIAL.format(SUBTASK=self.subtasks[subtask], TOKEN=self.token, RUN=run), json=[data])\n","            if response.status_code != 200:\n","                print(\"POST - Status Code \" + self.task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n","            else:\n","                print(\"Subtask {}: - run {}\".format(self.subtasks[subtask], run))\n","        \n","\n","    # Main thread\n","    def run_taskX(self, retries: int, backoff: float):\n","        # Get messages for taskX\n","        messages = self.get_messages(retries, backoff)\n","        # If there are no messages\n","        if len(messages) == 0:\n","            print(\"All rounds processed\")\n","            return\n","\n","        while len(messages) > 0:\n","            print(\"------------------- Processing round {}\".format(messages[0][\"round\"]))\n","            # Save subjects\n","            with open('./data/rounds_trial/round{}.json'.format(messages[0][\"round\"]), 'w+', encoding='utf8') as json_file:\n","                json.dump(messages, json_file, ensure_ascii=False)\n","\n","            # Calculate emissions for each prediction\n","            self.tracker.start()\n","\n","            # Your code\n","            \n","            emissions = self.tracker.stop()\n","            df = pd.read_csv(\"emissions.csv\")\n","            measurements = df.iloc[-1][self.relevant_cols].to_dict()\n","\n","            self.submit_decission(0, messages, measurements, retries, backoff) # taskXa\n","            self.submit_decission(1, messages, measurements, retries, backoff) # taskXb\n","            self.submit_decission(2, messages, measurements, retries, backoff) # taskXc\n","            self.submit_decission(3, messages, measurements, retries, backoff) # taskXd\n","\n","            # Only one GET request for each round\n","            messages = self.get_messages(retries, backoff)\n","\n","        print(\"All rounds processed\")"],"metadata":{"id":"l0kONpltS2R9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"gMXuHLciXIO3"}},{"cell_type":"markdown","source":["Please, replace the symbol 'X' by the desired task. For example, for task 1 it would be: task1, task1a and task1b."],"metadata":{"id":"KvhdFtEajwmp"}},{"cell_type":"code","source":["def download_data():\n","    download_messages_trial(\"taskX\", [\"taskXa\", \"taskXb\", \"taskXc\", \"taskXd\"], TOKEN)\n","\n","def get_post_data():\n","    # Emissions Tracker Config\n","    config = {\n","        \"save_to_file\": True,\n","        \"log_level\": \"DEBUG\",\n","        \"tracking_mode\": \"process\",\n","        \"output_dir\": \".\", \n","    }\n","    tracker = EmissionsTracker(**config)\n","\n","    number_runs = 3 # Max: 3\n","\n","    # Prediction period\n","    client_taskX = Client_taskX(\"taskX\", [\"taskXa\", \"taskXb\", \"taskXc\", \"taskXd\"], TOKEN, number_runs, tracker)\n","    client_taskX.run_taskX(5, 0.1)"],"metadata":{"id":"GZrDpxNAS6-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    download_data()\n","    #get_post_data()"],"metadata":{"id":"aKMWQ5buS8OK"},"execution_count":null,"outputs":[]}]}