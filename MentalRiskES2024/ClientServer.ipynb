{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Access the MentalRiskEs data and interact with the server\n","\n","This notebook has been developed by the [SINAI](https://sinai.ujaen.es/) research group for its usage in the [MentalRiskES](https://sites.google.com/view/mentalriskes2024/) evaluation campaign at IberLEF 2024.\n","\n","**NOTE 1**: Please visit the [MentalRiskES competition website](https://sites.google.com/view/mentalriskes2024/evaluation) to read the instructions about how to download the data and interact with the server to send the predictions of your system.\n","\n","**NOTE 2**: Along the code, please replace \"URL\" by the URL server and \"TOKEN\" by your personal token.\n","\n","Remember this is a support to help you to develop your own system of communication with our server. We recommend you to download it as a Python script instead of working directly on colab and adapt the code to your needs."],"metadata":{"id":"ttODwCFd8K0Q"}},{"cell_type":"markdown","source":["# Install CodeCarbon package\n","Read the [documentation](https://mlco2.github.io/codecarbon/) about the library if necessary. Remember that we provide a [CodeCarbon notebook](https://colab.research.google.com/drive/1boavnGOir0urui8qktbZaOmOV2pS5cn6?usp=sharing) with the example in its specific use in our competition.\n"],"metadata":{"id":"2DJN0pXx8W3-"}},{"cell_type":"code","source":["!pip install codecarbon"],"metadata":{"id":"wdvPWyc6x9cV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import libraries"],"metadata":{"id":"dqyN-7TcXbL8"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sqih7m6tN4MT"},"outputs":[],"source":["import requests, zipfile, io\n","from requests.adapters import HTTPAdapter, Retry\n","from typing import List, Dict\n","import random\n","import json\n","import os\n","import pandas as pd\n","from codecarbon import EmissionsTracker"]},{"cell_type":"markdown","source":["# Endpoints\n","These URL addresses are necessary for the connection to the server.\n","\n","**IMPORTANT:** Replace \"URL\" by the URL server and \"TOKEN\" by your user token."],"metadata":{"id":"CHGGrr3GXdIb"}},{"cell_type":"code","source":["URL = \"\"\n","TOKEN = \"your-token\"\n","\n","# Download endpoints\n","ENDPOINT_DOWNLOAD_TRIAL = URL+\"/{TASK}/download_trial/{TOKEN}\"\n","ENDPOINT_DOWNLOAD_TRAIN = URL+\"/{TASK}/download_train/{TOKEN}\"\n","\n","# Trial endpoints\n","ENDPOINT_GET_MESSAGES_TRIAL = URL+\"/{TASK}/getmessages_trial/{TOKEN}\"\n","ENDPOINT_SUBMIT_DECISIONS_TRIAL = URL+\"/{TASK}/submit_trial/{TOKEN}/{RUN}\"\n","\n","# Test endpoints\n","ENDPOINT_GET_MESSAGES = URL+\"/{TASK}/getmessages/{TOKEN}\"\n","ENDPOINT_SUBMIT_DECISIONS = URL+\"/{TASK}/submit/{TOKEN}/{RUN}\""],"metadata":{"id":"AdQPl8lbOKsg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Download Data\n","To download the data, you can make use of the **function defined in the following**.\n","\n","The following function download the trial data. To adapt it to download the train and test data, follow the instructions given in the [website of the competition](https://sites.google.com/view/mentalriskes2024/evaluation)."],"metadata":{"id":"WgHNiyxHR5AJ"}},{"cell_type":"code","source":["def download_messages_trial(task: str, token: str):\n","    \"\"\" Allows you to download the trial data of the task.\n","        Args:\n","          task (str): task from which the data is to be retrieved\n","          token (str): authentication token\n","    \"\"\"\n","\n","    response = requests.get(ENDPOINT_DOWNLOAD_TRIAL.format(TASK=task, TOKEN=token))\n","\n","    if response.status_code != 200:\n","        print(\"Trial - Status Code \" + task + \": \" + str(response.status_code) + \" - Error: \" + str(response.text))\n","    else:\n","      z = zipfile.ZipFile(io.BytesIO(response.content))\n","      os.makedirs(\"./data/{task}/trial/\".format(task=task))\n","      z.extractall(\"./data/{task}/trial/\".format(task=task))"],"metadata":{"id":"Uaeh23C5R1lG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Client Server\n","This class simulates communication with our server. The following code established the conection with the server client and simulate the GET and POST requests.\n","\n","**IMPORTANT NOTE:** Please pay attention to the basic functions and remember that it is only a base for your system."],"metadata":{"id":"VIqRCv3OS3Bn"}},{"cell_type":"code","source":["class Client_taskX:\n","    \"\"\" Client communicating with the official server.\n","        Attributes:\n","            task (str): task in which you wish to participate\n","            token (str): authentication token\n","            number_of_runs (int): number of systems. Must be 3 in order to advance to the next round.\n","            tracker (EmissionsTracker): object to calculate the carbon footprint in prediction\n","\n","    \"\"\"\n","    def __init__(self, task: str, token: str, number_of_runs: int, tracker: EmissionsTracker):\n","        self.task = task\n","        self.token = token\n","        self.number_of_runs = number_of_runs\n","        self.tracker = tracker\n","        # Required parameters\n","        self.relevant_cols = ['duration', 'emissions', 'cpu_energy', 'gpu_energy',\n","                              'ram_energy','energy_consumed', 'cpu_count', 'gpu_count',\n","                              'cpu_model', 'gpu_model', 'ram_total_size','country_iso_code']\n","\n","\n","    def get_messages(self, retries: int, backoff: float) -> Dict:\n","        \"\"\" Allows you to download the test data of the task by rounds.\n","            Here a GET request is sent to the server to extract the data.\n","            Args:\n","              retries (int): number of calls on the server connection\n","              backoff (float): time between retries\n","        \"\"\"\n","        session = requests.Session()\n","        retries = Retry(\n","                        total = retries,\n","                        backoff_factor = backoff,\n","                        status_forcelist = [500, 502, 503, 504]\n","                        )\n","        session.mount('https://', HTTPAdapter(max_retries=retries))\n","\n","        response = session.get(ENDPOINT_GET_MESSAGES_TRIAL.format(TASK=self.task, TOKEN=self.token)) # ENDPOINT FOR TRIAL\n","\n","        if response.status_code != 200:\n","          print(\"GET - Task {} - Status Code {} - Error: {}\".format(self.task, str(response.status_code), str(response.text)))\n","          return []\n","        else:\n","          return json.loads(response.content)\n","\n","    def submit_decission(self, messages: List[Dict], emissions: Dict, retries: int, backoff: float):\n","        \"\"\" Allows you to submit the decisions of the task by rounds.\n","            The POST requests are sent to the server to send predictions and carbon emission data\n","            Args:\n","              messages (List[Dict]): Message set of the current round\n","              emissions (Dict): carbon footprint generated in the prediction\n","              retries (int): number of calls on the server connection\n","              backoff (float): time between retries\n","        \"\"\"\n","        decisions = {}\n","        contexts = {}\n","        labels_task1_list = ['none', 'depression', 'anxiety'] # Example for task1 and task2\n","        labels_task2_list = [\"addiction\", \"emergency\", \"family\", \"work\", \"social\" ,\"other\", \"none\"] # Example for task2\n","\n","        # You must create the appropriate structure to send the predictions according to each task\n","        for message in messages:\n","            decisions[message[\"nick\"]] = random.choice(labels_task1_list)\n","            contexts[message[\"nick\"]] = random.choice(labels_task2_list)+\"#\"+random.choice(labels_task2_list)\n","\n","        data = {\n","            \"predictions\": decisions,\n","            \"contexts\":contexts,\n","            \"emissions\": emissions\n","        }\n","\n","        data = json.dumps(data)\n","\n","        # Session to POST request\n","        session = requests.Session()\n","        retries = Retry(\n","                        total = retries,\n","                        backoff_factor = backoff,\n","                        status_forcelist = [500, 502, 503, 504]\n","                        )\n","        session.mount('https://', HTTPAdapter(max_retries=retries))\n","\n","        for run in range(0, self.number_of_runs):\n","            # For each run, new decisions\n","            response = session.post(ENDPOINT_SUBMIT_DECISIONS_TRIAL.format(TASK=self.task, TOKEN=self.token, RUN=run), json=[data]) # ENDPOINT FOR TRIAL\n","\n","            if response.status_code != 200:\n","                print(\"POST - Task {} - Status Code {} - Error: {}\".format(self.task, str(response.status_code), str(response.text)))\n","                return\n","            else:\n","                print(\"POST - Task {} - run {} - Message: {}\".format(self.task, run, str(response.text)))\n","\n","\n","    def run_taskX(self, retries: int, backoff: float):\n","        \"\"\" Main thread\n","            Args:\n","              retries (int): number of calls on the server connection\n","              backoff (float): time between retries\n","        \"\"\"\n","        # Get messages for taskX\n","        messages = self.get_messages(retries, backoff)\n","\n","        # If there are no messages\n","        if len(messages) == 0:\n","            print(\"All rounds processed\")\n","            return\n","\n","        while len(messages) > 0:\n","            print(\"------------------- Processing round {}\".format(messages[0][\"round\"]))\n","            print(messages)\n","            # Save subjects\n","            with open('./data/rounds_trial/round{}.json'.format(messages[0][\"round\"]), 'w+', encoding='utf8') as json_file:\n","                json.dump(messages, json_file, ensure_ascii=False)\n","\n","            # Calculate emissions for each prediction\n","            self.tracker.start()\n","\n","            # Your code\n","\n","            emissions = self.tracker.stop()\n","            df = pd.read_csv(\"emissions.csv\")\n","            measurements = df.iloc[-1][self.relevant_cols].to_dict()\n","\n","            self.submit_decission(messages, measurements, retries, backoff)\n","\n","            # One GET request for each round\n","            messages = self.get_messages(retries, backoff)\n","\n","        print(\"All rounds processed\")"],"metadata":{"id":"l0kONpltS2R9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Main"],"metadata":{"id":"gMXuHLciXIO3"}},{"cell_type":"code","source":["def download_data(task: str, token: str):\n","    download_messages_trial(task, token)\n","\n","def get_post_data(task: str, token: str):\n","    # Emissions Tracker Config\n","    config = {\n","        \"save_to_file\": True,\n","        \"log_level\": \"DEBUG\",\n","        \"tracking_mode\": \"process\",\n","        \"output_dir\": \".\",\n","    }\n","    tracker = EmissionsTracker(**config)\n","\n","    number_runs = 3 # Max: 3\n","\n","    # Prediction period\n","    client_taskX = Client_taskX(task, token, number_runs, tracker)\n","    client_taskX.run_taskX(5, 0.1)"],"metadata":{"id":"GZrDpxNAS6-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","    download_data(\"task2\",TOKEN)\n","    #get_post_data(\"task2\",TOKEN)"],"metadata":{"id":"aKMWQ5buS8OK"},"execution_count":null,"outputs":[]}]}